from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from datetime import datetime
import re
import time

# ===== ë‚ ì§œ ì •ê·œí™” =====
def normalize_to_iso(date_str):
    date_str = re.sub(r"\(.*?\)", "", date_str)
    date_str = date_str.replace("~", "").replace(" ", "")
    if re.search(r'\d{1,2}:\d{2}', date_str):
        return None
    formats = [
        "%Yë…„%mì›”%dì¼", "%Y.%m.%d", "%Y-%m-%d",
        "%mì›”%dì¼", "%m.%d"
    ]
    for fmt in formats:
        try:
            dt = datetime.strptime(date_str, fmt)
            if "ë…„" not in fmt:
                dt = dt.replace(year=datetime.now().year)
            return dt.strftime("%Y-%m-%d")
        except:
            continue
    return None

def extract_event_dates(text):
    lines = text.splitlines()

    for line in lines:
        if any(kw in line for kw in ["ì¼ì‹œ", "ì¼ ì‹œ", "ìš´ì˜ê¸°ê°„", "í–‰ì‚¬ê¸°ê°„", "ì§„í–‰ê¸°ê°„", "êµìœ¡ê¸°ê°„", "í”„ë¡œê·¸ë¨ ê¸°ê°„"]):
            # ğŸ”¥ ê´„í˜¸ ì•ˆ ë¶€ê°€ì„¤ëª… ì œê±°
            line = re.sub(r"[\(\[\{][^\)\]\}]*[\)\]\}]", "", line)  # (ì›”), [ì •ë³´] ë“± ì œê±°
            line = re.sub(r"[ã€”ã€•]", "", line)  # ìœ ë‹ˆì½”ë“œ ê´„í˜¸ ì œê±°

            # ğŸ”¥ ë‚ ì§œ êµ¬ê°„ ì¶”ì¶œ
            date_range_match = re.search(
                r"(20\d{2}[.ë…„\s]*\d{1,2}[.ì›”\s]*\d{1,2}[ì¼]*)\s*[~âˆ¼ï¼ãƒ¼-]+\s*(\d{1,2}[.ì›”\s]*\d{1,2}[ì¼]*)",
                line
            )
            if date_range_match:
                start_raw = date_range_match.group(1)
                end_raw = date_range_match.group(2)
                start = normalize_to_iso(start_raw)
                if not re.search(r"20\d{2}", end_raw):
                    start_year = datetime.strptime(start, "%Y-%m-%d").year
                    end_raw = f"{start_year}ë…„{end_raw}"
                end = normalize_to_iso(end_raw)
                if start and end:
                    return [start, end]

    # ğŸ” fallback: ë‹¨ì¼ ë‚ ì§œë“¤ ì¶”ì¶œ
    patterns = [
        r'20\d{2}[./-]\d{1,2}[./-]\d{1,2}',
        r'20\d{2}ë…„\s?\d{1,2}ì›”\s?\d{1,2}ì¼',
        r'\d{1,2}ì›”\s?\d{1,2}ì¼',
        r'\d{1,2}[./]\d{1,2}'
    ]
    iso_dates = set()
    for line in lines:
        if "ì‹ ì²­" in line or "ì ‘ìˆ˜" in line or "ëª¨ì§‘" in line:
            continue
        for pattern in patterns:
            for match in re.findall(pattern, line):
                normalized = normalize_to_iso(match)
                if normalized:
                    iso_dates.add(normalized)

    return sorted(iso_dates) if iso_dates else None





#===== ì‹ ì²­ ë§ˆê°ì¼ ì¶”ì¶œ =======
def extract_deadline_date(text):
    lines = text.splitlines()
    for line in lines:
        if any(kw in line for kw in ["ì‹ ì²­ê¸°ê°„", "ëª¨ì§‘ê¸°ê°„", "ì ‘ìˆ˜ê¸°ê°„", "ì‹ ì²­ê¸°í•œ", "ëª¨ì§‘ê¸°í•œ", "ì œì¶œê¸°í•œ", "ì‹ ì²­ ë§ˆê°", "ì ‘ìˆ˜ ë§ˆê°", "ëª¨ì§‘ê¸°ê°„"]):
            matches = re.findall(r'(20\d{2}[./ë…„\s]*\d{1,2}[./ì›”\s]*\d{1,2}[ì¼\s]*)|(\d{1,2}[./ì›”\s]*\d{1,2}[ì¼\s]*)', line)
            dates = []
            for full_match in matches:
                date_raw = full_match[0] if full_match[0] else full_match[1]
                normalized = normalize_to_iso(date_raw)
                if normalized:
                    dates.append(normalized)
            if dates:
                return max(dates)
    return None


# ===== ê¸°íƒ€ í•„ë“œ ì¶”ì¶œ =====
def clean_prefix(line: str) -> str:
    return re.sub(r"^[ê°€-í£]\.|\d+[.)]|[-â€¢â—‹]\s*", "", line).strip()

def extract_target(text):
    keywords = ["ì°¸ê°€ëŒ€ìƒ", "ëª¨ì§‘ëŒ€ìƒ", "ì§€ì›ìê²©", "ëŒ€ìƒì", "ì‹ ì²­ìê²©", "ìê²©ìš”ê±´", "ëŒ€ìƒ"]
    for kw in keywords:
        for line in text.splitlines():
            if kw in line:
                return clean_prefix(line.strip())
    return None

def extract_apply_method(text):
    keywords = ["ì‹ ì²­ë°©ë²•", "ì§€ì›ë°©ë²•", "ì ‘ìˆ˜ë°©ë²•", "ì°¸ì—¬ì‹ ì²­", "ì‹ ì²­ ë°©ë²•", "ì§€ì› ë°©ë²•", "êµìœ¡ ì‹ ì²­"]
    for kw in keywords:
        for line in text.splitlines():
            if kw in line:
                return clean_prefix(line.strip())
    return None

def extract_locations(text):
    text = re.sub(r'\d{4}[./ë…„\s]*\d{1,2}[./ì›”\s]*\d{1,2}[ì¼\s]*', '', text)
    text = re.sub(r"\d{2}[./]\d{1,2}[./]\d{1,2}\.", "", text)

    postpositions = r"(ì—ì„œ|ì—|ì€|ëŠ”|ì´|ê°€|ìœ¼ë¡œ|ë¡œ)\b"

    # âœ… "ì¥ ì†Œ:"ì²˜ëŸ¼ ë„ì–´ì“°ê¸° ìˆëŠ” í˜•íƒœë„ ì¸ì‹
    match = re.search(r"ì¥\s*ì†Œ\s*[:ï¼š]?\s*(.*)", text)
    if match:
        raw_loc = match.group(1).strip()
        raw_loc = re.split(r"[,.ë“±]", raw_loc)[0].strip()
        if any(bad in raw_loc for bad in ["ì—†ìŒ", "ë¯¸ì •", "ë³„ë„", "ë¬¸ì˜", "ì¶”í›„"]):
            return None
        return raw_loc

    # ë°±ì—…: íŒ¨í„´ ê¸°ë°˜ ì¥ì†Œ ì¶”ì¶œ
    patterns = [
        r"(ë¯¸ë˜ë„ì„œê´€\s?[ê°€-í£\w\s\(\)]+)",
        r"(ê³µ6|ê³µ5|ê³µ4|ê³µ3|ê³µ2|ê³µ1|ê²½ì˜|ë„ì„œê´€|í˜¸ê´€|ê³µê³¼ëŒ€í•™|ê°•ì˜ì‹¤|â—‹â—‹ê´€|ë†1|ë†2|ë†3|BF\d)[\w\s\dí˜¸]*",
        r"(ì„œìš¸ëŒ€í•™êµ)", r"(ì¶˜ì²œ\s?[ê°€-í£\d]*)"
    ]
    for p in patterns:
        match = re.search(p, text)
        if match:
            location = re.split(postpositions, match.group().strip())[0].strip()
            if any(bad in location for bad in ["ì—†ìŒ", "ë¯¸ì •", "ë³„ë„", "ë¬¸ì˜", "ì¶”í›„"]):
                return None
            return location
    return None



    # ë°±ì—… íŒ¨í„´ ê¸°ë°˜ ì²˜ë¦¬
    patterns = [
        r"(ë¯¸ë˜ë„ì„œê´€\s?[ê°€-í£\w\s\(\)]+)",
        r"(ê³µ6|ê³µ5|ê³µ4|ê³µ3|ê³µ2|ê³µ1|ê²½ì˜|ë„ì„œê´€|í˜¸ê´€|ê³µê³¼ëŒ€í•™|ê°•ì˜ì‹¤|â—‹â—‹ê´€|ë†1|ë†2|ë†3|BF\d)[\w\s\dí˜¸]*",
        r"(ì„œìš¸ëŒ€í•™êµ)", r"(ì¶˜ì²œ\s?[ê°€-í£\d]*)"
    ]
    for p in patterns:
        match = re.search(p, text)
        if match:
            location = re.split(postpositions, match.group().strip())[0].strip()
            if any(bad in location for bad in ["ì—†ìŒ", "ë¯¸ì •", "ë³„ë„", "ë¬¸ì˜", "ì¶”í›„"]):
                return None
            return location
    return None

def classify_category(text):
    category_keywords = {
        "ê³µëª¨ì „": ["ê³µëª¨ì „", "ê²½ì§„ëŒ€íšŒ", "ì•„ì´ë””ì–´", "ì½˜í…ŒìŠ¤íŠ¸", "ì°½ì—…", "í•´ì»¤í†¤"],
        "ëŒ€ì™¸í™œë™": ["ëŒ€ì™¸í™œë™", "ì—°ìˆ˜", "í•´ì™¸", "ì¸í„´", "ë´‰ì‚¬", "êµë¥˜", "ì°¸ê°€ì ëª¨ì§‘"],
        "ë¹„êµê³¼": ["ë¹„êµê³¼", "íŠ¹ê°•", "ì›Œí¬ìˆ", "ì„¸ë¯¸ë‚˜", "ê°•ì—°", "ì†Œëª¨ì„", "ë¬¸í•´ë ¥", "ì—­ëŸ‰"]
    }
    for category, keywords in category_keywords.items():
        if any(k in text for k in keywords):
            return category
    return "ê¸°íƒ€"

# ===== í†µí•© ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜ =====
def extract_info(title, content):
    full_text = f"{title}\n{content}"
    return {
        "ì œëª©": title,
        "ë‚ ì§œ": extract_event_dates(full_text),
        "ì¥ì†Œ": extract_locations(full_text),
        "ì‹ ì²­ë°©ë²•": extract_apply_method(full_text),
        "ëŒ€ìƒ": extract_target(full_text),
        "ì‹ ì²­ë§ˆê°ì¼": extract_deadline_date(full_text),
        "ì¹´í…Œê³ ë¦¬": classify_category(full_text)
    }

# ===== í¬ë¡¤ë§ ì‹¤í–‰ =====
options = webdriver.ChromeOptions()
options.add_argument("--headless")
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
driver.get("https://padm.kangwon.ac.kr/padm/life/notice-department.do")
time.sleep(2)

all_hrefs = set()
page_num = 1

while page_num <= 3:
    WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "td.b-td-left.b-td-title a")))
    notice_links = driver.find_elements(By.CSS_SELECTOR, "td.b-td-left.b-td-title a")
    hrefs = [link.get_attribute("href") for link in notice_links if link.get_attribute("href")]
    all_hrefs.update(hrefs)

    try:
        next_page = driver.find_element(By.XPATH, f'//a[contains(@href, "goPage({page_num + 1}") or text()="{page_num + 1}"]')
        next_page.click()
        WebDriverWait(driver, 10).until(lambda d: str(page_num + 1) in d.page_source)
        time.sleep(1)
        page_num += 1
    except:
        break

print(f"\n[+] ì´ {len(all_hrefs)}ê°œì˜ ê³µì§€ ë§í¬ ìˆ˜ì§‘ ì™„ë£Œ.\n")

# ===== ê³µì§€ ìƒì„¸ ì¶”ì¶œ =====
i = 1
for url in all_hrefs:
    driver.get(url)
    try:
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, "p.b-title-box span")))
        title = driver.find_element(By.CSS_SELECTOR, "p.b-title-box span").text.strip()

        try:
            content = driver.find_element(By.CSS_SELECTOR, "div.b-content-box div.fr-view").text.strip()
        except:
            continue

        if re.fullmatch(r"\[?ê³µì§€\]?", title):
            continue

        info = extract_info(title, content)
        print(f"ğŸ”¹ [{i}] {info['ì œëª©']}")
        print(f"ğŸ“… ë‚ ì§œ: {info['ë‚ ì§œ'][0]} ~ {info['ë‚ ì§œ'][1]}" if info['ë‚ ì§œ'] and len(info['ë‚ ì§œ']) == 2 else f"ğŸ“… ë‚ ì§œ: {info['ë‚ ì§œ'][0]}" if info['ë‚ ì§œ'] else "ğŸ“… ë‚ ì§œ: ì—†ìŒ")
        print(f"ğŸ“ ì¥ì†Œ: {info['ì¥ì†Œ'] if info['ì¥ì†Œ'] else 'ì—†ìŒ'}")
        print(f"ğŸ‘¤ ëŒ€ìƒ: {info['ëŒ€ìƒ'] if info['ëŒ€ìƒ'] else 'ì—†ìŒ'}")
        print(f"ğŸ“¬ ì‹ ì²­ë°©ë²•: {info['ì‹ ì²­ë°©ë²•'] if info['ì‹ ì²­ë°©ë²•'] else 'ì—†ìŒ'}")
        print(f"â³ ì‹ ì²­ë§ˆê°ì¼: {info['ì‹ ì²­ë§ˆê°ì¼'] if info['ì‹ ì²­ë§ˆê°ì¼'] else 'ì—†ìŒ'}")
        print(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {info['ì¹´í…Œê³ ë¦¬']}")
        print("-" * 60 + "\n")
        i += 1

    except Exception as e:
        print(f"[!] [{i}] í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

driver.quit()
